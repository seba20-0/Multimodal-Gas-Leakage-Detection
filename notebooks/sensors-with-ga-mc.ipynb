{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11635786,"sourceType":"datasetVersion","datasetId":7300692}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, glob\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T23:05:59.439694Z","iopub.execute_input":"2025-05-04T23:05:59.439897Z","iopub.status.idle":"2025-05-04T23:06:17.199474Z","shell.execute_reply.started":"2025-05-04T23:05:59.439877Z","shell.execute_reply":"2025-05-04T23:06:17.198405Z"}},"outputs":[{"name":"stderr","text":"2025-05-04 23:06:02.265166: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746399962.514396      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746399962.586288      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def load_and_split_sensor_data(\n    csv_path: str,\n    test_size: float = 0.1,\n    val_size: float = 0.2,\n    random_state: int = 42\n):\n    \"\"\"\n    Load sensor CSV, preprocess (drop columns, encode labels, scale), and split into train/val/test.\n\n    Args:\n        csv_path: Path to the Gas Sensors Measurements CSV file.\n        test_size: Fraction of data reserved for final test set.\n        val_size: Fraction of remaining data reserved for validation.\n        random_state: Random seed for reproducibility.\n\n    Returns:\n        train_ds: tf.data.Dataset for training (features, labels).\n        val_ds: tf.data.Dataset for validation.\n        test_ds: tf.data.Dataset for testing.\n    \"\"\"\n    # 1) Load and clean\n    df = pd.read_csv(csv_path)\n    # drop unused columns\n    df = df.drop(columns=[\"Serial Number\", \"Corresponding Image Name\"], errors='ignore')\n    # encode labels\n    df['Gas'] = df['Gas'].astype('category').cat.codes\n\n    # 2) Extract features and labels\n    feature_cols = [c for c in df.columns if c != 'Gas']\n    X = df[feature_cols].values.astype('float32')\n    y = df['Gas'].values.astype('int32')\n\n    # 3) Scale features\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    # 4) Split into train+val and test\n    X_temp, X_test, y_temp, y_test = train_test_split(\n        X_scaled, y, test_size=test_size, stratify=y, random_state=random_state\n    )\n    # Split train_temp into train and val\n    val_fraction = val_size / (1 - test_size)\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_temp, y_temp, test_size=val_fraction,\n        stratify=y_temp, random_state=random_state\n    )\n\n    # 5) Build tf.data datasets\n    def make_ds(features, labels, batch_size=32, shuffle=False):\n        ds = tf.data.Dataset.from_tensor_slices((features, labels))\n        if shuffle:\n            ds = ds.shuffle(buffer_size=len(features), seed=random_state)\n        return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n    batch_size = 32\n    train_ds = make_ds(X_train, y_train, batch_size, shuffle=True)\n    val_ds   = make_ds(X_val,   y_val,   batch_size, shuffle=False)\n    test_ds  = make_ds(X_test,  y_test,  batch_size, shuffle=False)\n\n    return train_ds, val_ds, test_ds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T23:06:17.201221Z","iopub.execute_input":"2025-05-04T23:06:17.201769Z","iopub.status.idle":"2025-05-04T23:06:17.211389Z","shell.execute_reply.started":"2025-05-04T23:06:17.201747Z","shell.execute_reply":"2025-05-04T23:06:17.210482Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_ds, val_ds, test_ds = load_and_split_sensor_data(\"/kaggle/input/gas-dataset/zkwgkjkjn9-2/Gas Sensors Measurements/Gas_Sensors_Measurements.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T23:06:43.930453Z","iopub.execute_input":"2025-05-04T23:06:43.930750Z","iopub.status.idle":"2025-05-04T23:06:44.073207Z","shell.execute_reply.started":"2025-05-04T23:06:43.930727Z","shell.execute_reply":"2025-05-04T23:06:44.072256Z"}},"outputs":[{"name":"stderr","text":"2025-05-04 23:06:44.002798: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"class RandomSensorDropout(tf.keras.layers.Layer):\n    \"\"\"\n    Layer that randomly zeros individual sensor channels with a given rate during training.\n    Supports proper serialization.\n    \"\"\"\n    def __init__(self, rate=0.3, **kwargs):\n        super().__init__(**kwargs)\n        self.rate = rate\n\n    def call(self, inputs, training=False):\n        if training and self.rate > 0.0:\n            mask = tf.cast(tf.random.uniform(tf.shape(inputs)) > self.rate, inputs.dtype)\n            return inputs * mask\n        return inputs\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"rate\": self.rate})\n        return config\n    \n\n# --------------- Monte Carlo Dropout Layers ---------------------    \nclass MCDropout(tf.keras.layers.Dropout):\n    \"\"\"\n    Dropout that is active both at train *and* inference time,\n    so we can sample N stochastic forward passes.\n    \"\"\"\n    def call(self, inputs, training=None):\n        # Force dropout even in inference\n        return super().call(inputs, training=True)    \n\n# --------------- Sensor Model ---------------------\n\ndef build_sensor_model(\n    input_dim=7,\n    sensor_dropout_rate=0.3,\n    layer_dropout = 0.5,\n    hidden_units=(64, 32),\n    output_units=4,\n    lr=1e-4\n):\n    \"\"\"\n    Sensor-only MLP with RandomSensorDropout option for ablation.\n    \"\"\"\n    inp = tf.keras.Input(shape=(input_dim,), name=\"sensor_input\")\n    x = RandomSensorDropout(sensor_dropout_rate, name=\"sensor_dropout\")(inp)\n    x = tf.keras.layers.Dense(hidden_units[0], activation=\"relu\")(x)\n    x = MCDropout(layer_dropout)(x)\n    x = tf.keras.layers.Dense(hidden_units[1], activation=\"relu\")(x)\n    x = MCDropout(layer_dropout)(x)\n    out = tf.keras.layers.Dense(output_units, activation=\"softmax\", name=\"output\")(x)\n\n    model = tf.keras.Model(inp, out, name=\"sensor_only\")\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(lr),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T23:09:14.736437Z","iopub.execute_input":"2025-05-04T23:09:14.736752Z","iopub.status.idle":"2025-05-04T23:09:14.821580Z","shell.execute_reply.started":"2025-05-04T23:09:14.736730Z","shell.execute_reply":"2025-05-04T23:09:14.820732Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# With default parameters","metadata":{}},{"cell_type":"code","source":"def predict_mc(model, dataset, T=50):\n    all_preds = []\n    all_labels = []\n    for sens_batch, lbl_batch in dataset:\n        preds_t = [model(sens_batch).numpy() for _ in range(T)]\n        preds_t = np.stack(preds_t, axis=0)  # (T, batch, classes)\n        mean_preds = preds_t.mean(axis=0)    # (batch, classes)\n        all_preds.append(mean_preds)\n        all_labels.append(lbl_batch.numpy())\n    all_preds = np.concatenate(all_preds, axis=0)\n    all_labels = np.concatenate(all_labels, axis=0)\n    y_pred = np.argmax(all_preds, axis=1)\n    return np.mean(y_pred == all_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T23:09:19.069237Z","iopub.execute_input":"2025-05-04T23:09:19.069553Z","iopub.status.idle":"2025-05-04T23:09:19.075851Z","shell.execute_reply.started":"2025-05-04T23:09:19.069528Z","shell.execute_reply":"2025-05-04T23:09:19.074767Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = build_sensor_model()\nckpt_path = \"best_sensor_dropout.keras\"\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n        ckpt_path,\n        monitor=\"val_accuracy\",\n        mode=\"max\",\n        save_best_only=True,\n        verbose=0\n    )\nmodel.fit(train_ds, validation_data=val_ds, epochs=100 , callbacks=[checkpoint_cb])\nbest_model = tf.keras.models.load_model(\n        ckpt_path,\n        custom_objects={\"RandomSensorDropout\": RandomSensorDropout, \"MCDropout\": MCDropout}\n    )\nacc = predict_mc(best_model, test_ds, T=50)\nprint(\"testing accuracy is \",acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T23:11:30.947714Z","iopub.execute_input":"2025-05-04T23:11:30.947999Z","iopub.status.idle":"2025-05-04T23:12:07.901525Z","shell.execute_reply.started":"2025-05-04T23:11:30.947981Z","shell.execute_reply":"2025-05-04T23:12:07.900494Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3026 - loss: 1.4142 - val_accuracy: 0.4039 - val_loss: 1.2778\nEpoch 2/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4143 - loss: 1.2750 - val_accuracy: 0.5141 - val_loss: 1.1040\nEpoch 3/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5047 - loss: 1.1727 - val_accuracy: 0.5891 - val_loss: 0.9867\nEpoch 4/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5371 - loss: 1.0908 - val_accuracy: 0.6523 - val_loss: 0.8756\nEpoch 5/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6065 - loss: 0.9864 - val_accuracy: 0.6492 - val_loss: 0.8311\nEpoch 6/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6300 - loss: 0.9116 - val_accuracy: 0.7039 - val_loss: 0.7160\nEpoch 7/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6514 - loss: 0.8543 - val_accuracy: 0.6891 - val_loss: 0.6844\nEpoch 8/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6600 - loss: 0.8041 - val_accuracy: 0.7125 - val_loss: 0.6384\nEpoch 9/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6650 - loss: 0.7708 - val_accuracy: 0.7141 - val_loss: 0.5947\nEpoch 10/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6631 - loss: 0.7486 - val_accuracy: 0.7234 - val_loss: 0.5774\nEpoch 11/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6847 - loss: 0.6965 - val_accuracy: 0.7328 - val_loss: 0.5352\nEpoch 12/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6860 - loss: 0.6858 - val_accuracy: 0.7406 - val_loss: 0.5108\nEpoch 13/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6708 - loss: 0.6541 - val_accuracy: 0.7437 - val_loss: 0.5114\nEpoch 14/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6776 - loss: 0.6479 - val_accuracy: 0.7461 - val_loss: 0.4783\nEpoch 15/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7066 - loss: 0.6181 - val_accuracy: 0.7523 - val_loss: 0.4627\nEpoch 16/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7090 - loss: 0.6192 - val_accuracy: 0.7641 - val_loss: 0.4440\nEpoch 17/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6958 - loss: 0.6111 - val_accuracy: 0.7719 - val_loss: 0.4355\nEpoch 18/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7030 - loss: 0.5919 - val_accuracy: 0.7406 - val_loss: 0.4456\nEpoch 19/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7076 - loss: 0.5802 - val_accuracy: 0.7484 - val_loss: 0.4473\nEpoch 20/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.5760 - val_accuracy: 0.7688 - val_loss: 0.4165\nEpoch 21/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6988 - loss: 0.5809 - val_accuracy: 0.7523 - val_loss: 0.4217\nEpoch 22/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7109 - loss: 0.5668 - val_accuracy: 0.7563 - val_loss: 0.4104\nEpoch 23/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.5489 - val_accuracy: 0.7656 - val_loss: 0.4049\nEpoch 24/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7247 - loss: 0.5514 - val_accuracy: 0.7703 - val_loss: 0.4010\nEpoch 25/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6987 - loss: 0.5511 - val_accuracy: 0.7727 - val_loss: 0.3859\nEpoch 26/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.5240 - val_accuracy: 0.7578 - val_loss: 0.4019\nEpoch 27/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.5111 - val_accuracy: 0.7742 - val_loss: 0.3848\nEpoch 28/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.5207 - val_accuracy: 0.7844 - val_loss: 0.3789\nEpoch 29/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5267 - val_accuracy: 0.7641 - val_loss: 0.3908\nEpoch 30/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.5138 - val_accuracy: 0.7672 - val_loss: 0.3897\nEpoch 31/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.5147 - val_accuracy: 0.7680 - val_loss: 0.3743\nEpoch 32/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.5154 - val_accuracy: 0.7789 - val_loss: 0.3774\nEpoch 33/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7279 - loss: 0.5165 - val_accuracy: 0.7688 - val_loss: 0.3816\nEpoch 34/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7496 - loss: 0.4943 - val_accuracy: 0.7719 - val_loss: 0.3812\nEpoch 35/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5193 - val_accuracy: 0.7695 - val_loss: 0.3774\nEpoch 36/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.5076 - val_accuracy: 0.7859 - val_loss: 0.3616\nEpoch 37/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5126 - val_accuracy: 0.7937 - val_loss: 0.3626\nEpoch 38/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7446 - loss: 0.4946 - val_accuracy: 0.7641 - val_loss: 0.3690\nEpoch 39/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7426 - loss: 0.4972 - val_accuracy: 0.7680 - val_loss: 0.3667\nEpoch 40/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.4896 - val_accuracy: 0.7766 - val_loss: 0.3657\nEpoch 41/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.4902 - val_accuracy: 0.7781 - val_loss: 0.3659\nEpoch 42/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7442 - loss: 0.4870 - val_accuracy: 0.7922 - val_loss: 0.3596\nEpoch 43/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.5068 - val_accuracy: 0.7977 - val_loss: 0.3540\nEpoch 44/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.4985 - val_accuracy: 0.7758 - val_loss: 0.3615\nEpoch 45/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 0.4684 - val_accuracy: 0.7883 - val_loss: 0.3572\nEpoch 46/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.4866 - val_accuracy: 0.7789 - val_loss: 0.3506\nEpoch 47/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.5127 - val_accuracy: 0.7930 - val_loss: 0.3568\nEpoch 48/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7533 - loss: 0.4778 - val_accuracy: 0.7711 - val_loss: 0.3589\nEpoch 49/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7551 - loss: 0.4794 - val_accuracy: 0.7859 - val_loss: 0.3558\nEpoch 50/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7549 - loss: 0.4806 - val_accuracy: 0.8086 - val_loss: 0.3427\nEpoch 51/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.4778 - val_accuracy: 0.7961 - val_loss: 0.3489\nEpoch 52/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7456 - loss: 0.4808 - val_accuracy: 0.7898 - val_loss: 0.3487\nEpoch 53/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7611 - loss: 0.4872 - val_accuracy: 0.8016 - val_loss: 0.3427\nEpoch 54/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7497 - loss: 0.4734 - val_accuracy: 0.7969 - val_loss: 0.3426\nEpoch 55/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7628 - loss: 0.4617 - val_accuracy: 0.7977 - val_loss: 0.3481\nEpoch 56/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7519 - loss: 0.4897 - val_accuracy: 0.8055 - val_loss: 0.3416\nEpoch 57/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7533 - loss: 0.4818 - val_accuracy: 0.7875 - val_loss: 0.3541\nEpoch 58/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7521 - loss: 0.4765 - val_accuracy: 0.8117 - val_loss: 0.3419\nEpoch 59/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7553 - loss: 0.4689 - val_accuracy: 0.7883 - val_loss: 0.3426\nEpoch 60/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7611 - loss: 0.4717 - val_accuracy: 0.7844 - val_loss: 0.3430\nEpoch 61/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7556 - loss: 0.4697 - val_accuracy: 0.8047 - val_loss: 0.3426\nEpoch 62/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7466 - loss: 0.4769 - val_accuracy: 0.8000 - val_loss: 0.3460\nEpoch 63/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7625 - loss: 0.4584 - val_accuracy: 0.8070 - val_loss: 0.3427\nEpoch 64/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7732 - loss: 0.4705 - val_accuracy: 0.8047 - val_loss: 0.3355\nEpoch 65/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7440 - loss: 0.4728 - val_accuracy: 0.7906 - val_loss: 0.3447\nEpoch 66/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7578 - loss: 0.4560 - val_accuracy: 0.7977 - val_loss: 0.3430\nEpoch 67/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7660 - loss: 0.4687 - val_accuracy: 0.8055 - val_loss: 0.3405\nEpoch 68/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7687 - loss: 0.4690 - val_accuracy: 0.8078 - val_loss: 0.3364\nEpoch 69/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7590 - loss: 0.4745 - val_accuracy: 0.8031 - val_loss: 0.3379\nEpoch 70/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7695 - loss: 0.4593 - val_accuracy: 0.7977 - val_loss: 0.3468\nEpoch 71/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7818 - loss: 0.4434 - val_accuracy: 0.8102 - val_loss: 0.3300\nEpoch 72/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.4641 - val_accuracy: 0.8195 - val_loss: 0.3339\nEpoch 73/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7623 - loss: 0.4595 - val_accuracy: 0.8102 - val_loss: 0.3352\nEpoch 74/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 0.4720 - val_accuracy: 0.7977 - val_loss: 0.3467\nEpoch 75/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7640 - loss: 0.4573 - val_accuracy: 0.7914 - val_loss: 0.3465\nEpoch 76/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7667 - loss: 0.4491 - val_accuracy: 0.8086 - val_loss: 0.3312\nEpoch 77/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7542 - loss: 0.4716 - val_accuracy: 0.8203 - val_loss: 0.3314\nEpoch 78/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7729 - loss: 0.4490 - val_accuracy: 0.7930 - val_loss: 0.3416\nEpoch 79/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7707 - loss: 0.4498 - val_accuracy: 0.8125 - val_loss: 0.3359\nEpoch 80/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7666 - loss: 0.4578 - val_accuracy: 0.8125 - val_loss: 0.3330\nEpoch 81/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7889 - loss: 0.4359 - val_accuracy: 0.8086 - val_loss: 0.3338\nEpoch 82/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7610 - loss: 0.4713 - val_accuracy: 0.8023 - val_loss: 0.3410\nEpoch 83/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7726 - loss: 0.4621 - val_accuracy: 0.8156 - val_loss: 0.3286\nEpoch 84/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7754 - loss: 0.4372 - val_accuracy: 0.7992 - val_loss: 0.3347\nEpoch 85/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7684 - loss: 0.4618 - val_accuracy: 0.8164 - val_loss: 0.3272\nEpoch 86/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.4723 - val_accuracy: 0.8094 - val_loss: 0.3328\nEpoch 87/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7795 - loss: 0.4567 - val_accuracy: 0.8250 - val_loss: 0.3237\nEpoch 88/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.4505 - val_accuracy: 0.8023 - val_loss: 0.3428\nEpoch 89/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7624 - loss: 0.4616 - val_accuracy: 0.8227 - val_loss: 0.3263\nEpoch 90/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7854 - loss: 0.4288 - val_accuracy: 0.7969 - val_loss: 0.3298\nEpoch 91/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7575 - loss: 0.4552 - val_accuracy: 0.7984 - val_loss: 0.3336\nEpoch 92/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7635 - loss: 0.4603 - val_accuracy: 0.8203 - val_loss: 0.3277\nEpoch 93/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7700 - loss: 0.4455 - val_accuracy: 0.8125 - val_loss: 0.3268\nEpoch 94/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7794 - loss: 0.4517 - val_accuracy: 0.8219 - val_loss: 0.3195\nEpoch 95/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7779 - loss: 0.4385 - val_accuracy: 0.8250 - val_loss: 0.3278\nEpoch 96/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7671 - loss: 0.4486 - val_accuracy: 0.8242 - val_loss: 0.3244\nEpoch 97/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7715 - loss: 0.4342 - val_accuracy: 0.8211 - val_loss: 0.3313\nEpoch 98/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7654 - loss: 0.4568 - val_accuracy: 0.8336 - val_loss: 0.3224\nEpoch 99/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7819 - loss: 0.4306 - val_accuracy: 0.8141 - val_loss: 0.3287\nEpoch 100/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7796 - loss: 0.4349 - val_accuracy: 0.7984 - val_loss: 0.3371\ntesting accuracy is  0.875\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# With parameters obtained from GA","metadata":{}},{"cell_type":"code","source":"model = build_sensor_model(layer_dropout = 0.036,\n    hidden_units=(224,240),\n    lr=7.07e-04)\nckpt_path = \"best_sensor_dropout.keras\"\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n        ckpt_path,\n        monitor=\"val_accuracy\",\n        mode=\"max\",\n        save_best_only=True,\n        verbose=0\n    )\nmodel.fit(train_ds, validation_data=val_ds, epochs=100 , callbacks=[checkpoint_cb])\nbest_model = tf.keras.models.load_model(\n        ckpt_path,\n        custom_objects={\"RandomSensorDropout\": RandomSensorDropout, \"MCDropout\": MCDropout}\n    )\nacc = predict_mc(best_model, test_ds, T=50)\nprint(\"testing accuracy is \",acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T23:15:14.083923Z","iopub.execute_input":"2025-05-04T23:15:14.084293Z","iopub.status.idle":"2025-05-04T23:16:01.239582Z","shell.execute_reply.started":"2025-05-04T23:15:14.084263Z","shell.execute_reply":"2025-05-04T23:16:01.238762Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7171 - loss: 0.7626 - val_accuracy: 0.8891 - val_loss: 0.2585\nEpoch 2/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.3867 - val_accuracy: 0.8883 - val_loss: 0.2246\nEpoch 3/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8391 - loss: 0.3357 - val_accuracy: 0.9109 - val_loss: 0.1999\nEpoch 4/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8562 - loss: 0.3173 - val_accuracy: 0.9250 - val_loss: 0.1945\nEpoch 5/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.2899 - val_accuracy: 0.9227 - val_loss: 0.1868\nEpoch 6/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8771 - loss: 0.2833 - val_accuracy: 0.9219 - val_loss: 0.1890\nEpoch 7/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8852 - loss: 0.2704 - val_accuracy: 0.9219 - val_loss: 0.1770\nEpoch 8/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.2703 - val_accuracy: 0.9234 - val_loss: 0.1731\nEpoch 9/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.2371 - val_accuracy: 0.9281 - val_loss: 0.1663\nEpoch 10/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.2646 - val_accuracy: 0.9203 - val_loss: 0.1846\nEpoch 11/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.2449 - val_accuracy: 0.9344 - val_loss: 0.1719\nEpoch 12/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.2403 - val_accuracy: 0.9305 - val_loss: 0.1615\nEpoch 13/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8866 - loss: 0.2571 - val_accuracy: 0.9328 - val_loss: 0.1642\nEpoch 14/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8976 - loss: 0.2370 - val_accuracy: 0.9156 - val_loss: 0.1760\nEpoch 15/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.2349 - val_accuracy: 0.9273 - val_loss: 0.1697\nEpoch 16/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8990 - loss: 0.2438 - val_accuracy: 0.9320 - val_loss: 0.1592\nEpoch 17/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.2303 - val_accuracy: 0.9203 - val_loss: 0.1678\nEpoch 18/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.2169 - val_accuracy: 0.9344 - val_loss: 0.1518\nEpoch 19/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.2327 - val_accuracy: 0.9297 - val_loss: 0.1652\nEpoch 20/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8988 - loss: 0.2264 - val_accuracy: 0.9367 - val_loss: 0.1544\nEpoch 21/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.2221 - val_accuracy: 0.9242 - val_loss: 0.1663\nEpoch 22/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2137 - val_accuracy: 0.9320 - val_loss: 0.1482\nEpoch 23/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.2263 - val_accuracy: 0.9289 - val_loss: 0.1653\nEpoch 24/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2171 - val_accuracy: 0.9328 - val_loss: 0.1467\nEpoch 25/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.2213 - val_accuracy: 0.9398 - val_loss: 0.1574\nEpoch 26/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.2330 - val_accuracy: 0.9344 - val_loss: 0.1488\nEpoch 27/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.2311 - val_accuracy: 0.9367 - val_loss: 0.1441\nEpoch 28/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2180 - val_accuracy: 0.9367 - val_loss: 0.1545\nEpoch 29/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2088 - val_accuracy: 0.9352 - val_loss: 0.1675\nEpoch 30/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2043 - val_accuracy: 0.9328 - val_loss: 0.1390\nEpoch 31/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2077 - val_accuracy: 0.9312 - val_loss: 0.1501\nEpoch 32/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.2136 - val_accuracy: 0.9375 - val_loss: 0.1412\nEpoch 33/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2014 - val_accuracy: 0.9383 - val_loss: 0.1390\nEpoch 34/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2051 - val_accuracy: 0.9359 - val_loss: 0.1394\nEpoch 35/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2019 - val_accuracy: 0.9406 - val_loss: 0.1374\nEpoch 36/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2043 - val_accuracy: 0.9406 - val_loss: 0.1389\nEpoch 37/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.1965 - val_accuracy: 0.9367 - val_loss: 0.1507\nEpoch 38/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.2204 - val_accuracy: 0.9391 - val_loss: 0.1395\nEpoch 39/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2034 - val_accuracy: 0.9352 - val_loss: 0.1379\nEpoch 40/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2144 - val_accuracy: 0.9336 - val_loss: 0.1493\nEpoch 41/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2024 - val_accuracy: 0.9344 - val_loss: 0.1400\nEpoch 42/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2123 - val_accuracy: 0.9438 - val_loss: 0.1332\nEpoch 43/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2122 - val_accuracy: 0.9406 - val_loss: 0.1303\nEpoch 44/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2050 - val_accuracy: 0.9430 - val_loss: 0.1336\nEpoch 45/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2014 - val_accuracy: 0.9375 - val_loss: 0.1324\nEpoch 46/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.1990 - val_accuracy: 0.9375 - val_loss: 0.1509\nEpoch 47/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2043 - val_accuracy: 0.9398 - val_loss: 0.1444\nEpoch 48/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2164 - val_accuracy: 0.9359 - val_loss: 0.1368\nEpoch 49/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2094 - val_accuracy: 0.9414 - val_loss: 0.1386\nEpoch 50/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.1994 - val_accuracy: 0.9422 - val_loss: 0.1284\nEpoch 51/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.1979 - val_accuracy: 0.9266 - val_loss: 0.1689\nEpoch 52/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.1934 - val_accuracy: 0.9469 - val_loss: 0.1231\nEpoch 53/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9280 - loss: 0.1807 - val_accuracy: 0.9430 - val_loss: 0.1384\nEpoch 54/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.1811 - val_accuracy: 0.9398 - val_loss: 0.1366\nEpoch 55/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.1909 - val_accuracy: 0.9477 - val_loss: 0.1335\nEpoch 56/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.1859 - val_accuracy: 0.9375 - val_loss: 0.1360\nEpoch 57/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9225 - loss: 0.1880 - val_accuracy: 0.9430 - val_loss: 0.1353\nEpoch 58/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.1984 - val_accuracy: 0.9492 - val_loss: 0.1329\nEpoch 59/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.1811 - val_accuracy: 0.9445 - val_loss: 0.1289\nEpoch 60/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.1954 - val_accuracy: 0.9445 - val_loss: 0.1274\nEpoch 61/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.1837 - val_accuracy: 0.9406 - val_loss: 0.1250\nEpoch 62/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.1981 - val_accuracy: 0.9453 - val_loss: 0.1244\nEpoch 63/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2004 - val_accuracy: 0.9367 - val_loss: 0.1339\nEpoch 64/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.1919 - val_accuracy: 0.9414 - val_loss: 0.1331\nEpoch 65/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.1847 - val_accuracy: 0.9406 - val_loss: 0.1302\nEpoch 66/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2020 - val_accuracy: 0.9508 - val_loss: 0.1202\nEpoch 67/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.1926 - val_accuracy: 0.9445 - val_loss: 0.1255\nEpoch 68/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.1925 - val_accuracy: 0.9438 - val_loss: 0.1257\nEpoch 69/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.1864 - val_accuracy: 0.9383 - val_loss: 0.1356\nEpoch 70/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.1934 - val_accuracy: 0.9445 - val_loss: 0.1272\nEpoch 71/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.1860 - val_accuracy: 0.9430 - val_loss: 0.1262\nEpoch 72/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.1834 - val_accuracy: 0.9406 - val_loss: 0.1405\nEpoch 73/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.1874 - val_accuracy: 0.9453 - val_loss: 0.1259\nEpoch 74/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.1744 - val_accuracy: 0.9453 - val_loss: 0.1260\nEpoch 75/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.1881 - val_accuracy: 0.9438 - val_loss: 0.1328\nEpoch 76/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.1890 - val_accuracy: 0.9445 - val_loss: 0.1245\nEpoch 77/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.1922 - val_accuracy: 0.9430 - val_loss: 0.1239\nEpoch 78/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2006 - val_accuracy: 0.9383 - val_loss: 0.1282\nEpoch 79/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.1837 - val_accuracy: 0.9516 - val_loss: 0.1166\nEpoch 80/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.1979 - val_accuracy: 0.9516 - val_loss: 0.1263\nEpoch 81/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.1926 - val_accuracy: 0.9477 - val_loss: 0.1214\nEpoch 82/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9204 - loss: 0.1823 - val_accuracy: 0.9484 - val_loss: 0.1193\nEpoch 83/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.1885 - val_accuracy: 0.9484 - val_loss: 0.1242\nEpoch 84/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.1894 - val_accuracy: 0.9430 - val_loss: 0.1290\nEpoch 85/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.1883 - val_accuracy: 0.9430 - val_loss: 0.1282\nEpoch 86/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9290 - loss: 0.1769 - val_accuracy: 0.9469 - val_loss: 0.1189\nEpoch 87/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.1738 - val_accuracy: 0.9453 - val_loss: 0.1218\nEpoch 88/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.1933 - val_accuracy: 0.9445 - val_loss: 0.1215\nEpoch 89/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.1890 - val_accuracy: 0.9406 - val_loss: 0.1274\nEpoch 90/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.1865 - val_accuracy: 0.9469 - val_loss: 0.1193\nEpoch 91/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.1844 - val_accuracy: 0.9461 - val_loss: 0.1155\nEpoch 92/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.1732 - val_accuracy: 0.9477 - val_loss: 0.1303\nEpoch 93/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.1749 - val_accuracy: 0.9469 - val_loss: 0.1196\nEpoch 94/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.1721 - val_accuracy: 0.9516 - val_loss: 0.1214\nEpoch 95/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.1739 - val_accuracy: 0.9430 - val_loss: 0.1196\nEpoch 96/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.1873 - val_accuracy: 0.9523 - val_loss: 0.1148\nEpoch 97/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.1691 - val_accuracy: 0.9516 - val_loss: 0.1168\nEpoch 98/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9279 - loss: 0.1822 - val_accuracy: 0.9547 - val_loss: 0.1178\nEpoch 99/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.1788 - val_accuracy: 0.9531 - val_loss: 0.1122\nEpoch 100/100\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.1797 - val_accuracy: 0.9523 - val_loss: 0.1209\ntesting accuracy is  0.9640625\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
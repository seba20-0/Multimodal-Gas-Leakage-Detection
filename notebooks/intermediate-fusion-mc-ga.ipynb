{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11635786,"sourceType":"datasetVersion","datasetId":7300692}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:35:06.270035Z","iopub.execute_input":"2025-05-04T22:35:06.270844Z","iopub.status.idle":"2025-05-04T22:35:19.510902Z","shell.execute_reply.started":"2025-05-04T22:35:06.270809Z","shell.execute_reply":"2025-05-04T22:35:19.510367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_and_split_multimodal_data(\n    sensor_csv_path: str,\n    image_data_dir: str,\n    test_size: float = 0.1,\n    val_size: float = 0.2,\n    batch_size: int = 32,\n    img_size: tuple = (120, 160),\n    random_state: int = 42\n):\n    \"\"\"\n    Load and split both sensor CSV and image folders into multimodal tf.data.Datasets.\n\n    Args:\n        sensor_csv_path: Path to the gas sensor CSV.\n        image_data_dir: Base directory of image class subfolders.\n        test_size: Fraction of data reserved for testing.\n        val_size: Fraction of remaining data reserved for validation.\n        batch_size: Batch size for tf.data pipelines.\n        img_size: Size to resize images to (height, width).\n        random_state: Seed for reproducibility.\n\n    Returns:\n        train_ds, val_ds, test_ds: tf.data.Dataset yielding ((sensor, image), label).\n    \"\"\"\n    # 1) Load sensor CSV\n    sdf = pd.read_csv(sensor_csv_path)\n    sdf = sdf.drop(columns=[\"Serial Number\"], errors='ignore')\n    sdf['Gas'] = sdf['Gas'].astype('category').cat.codes\n\n    # Build image filename column\n    sdf['Image_File'] = sdf['Corresponding Image Name'].astype(str) + \".png\"\n\n    # Extract sensor features and labels\n    sensor_cols = [c for c in sdf.columns if c not in ['Gas', 'Corresponding Image Name', 'Image_File']]\n    sensors = sdf[sensor_cols].values.astype('float32')\n    labels = sdf['Gas'].values.astype('int32')\n\n    # Normalize sensors\n    scaler = StandardScaler().fit(sensors)\n    sensors = scaler.transform(sensors)\n\n    # Map image names to full paths\n    base = image_data_dir\n    def find_path(fname):\n        for cls in os.listdir(base):\n            p = os.path.join(base, cls, fname)\n            if os.path.exists(p):\n                return p\n        return None\n\n    paths = np.array(sdf['Image_File'].map(find_path))\n    valid = ~pd.isna(paths)\n\n    sensors = sensors[valid]\n    paths   = paths[valid]\n    labels  = labels[valid]\n\n    # Split multimodal arrays\n    X_temp, X_test, S_temp, S_test, y_temp, y_test = train_test_split(\n        paths, sensors, labels,\n        test_size=test_size, stratify=labels, random_state=random_state\n    )\n    val_frac = val_size / (1 - test_size)\n    X_train, X_val, S_train, S_val, y_train, y_val = train_test_split(\n        X_temp, S_temp, y_temp,\n        test_size=val_frac, stratify=y_temp, random_state=random_state\n    )\n\n    # Define loader\n    def loader(path, sens, lab):\n        img = tf.io.read_file(path)\n        img = tf.image.decode_png(img, channels=3)\n        img = tf.image.resize(img, img_size)\n        img = tf.cast(img, tf.float32) / 255.0\n        sens = tf.cast(sens, tf.float32)\n        return (sens, img), lab\n\n    # Build tf.data datasets\n    def make_ds(paths, sensors, labels, shuffle=False):\n        ds = tf.data.Dataset.from_tensor_slices((paths, sensors, labels))\n        ds = ds.map(loader, num_parallel_calls=tf.data.AUTOTUNE)\n        if shuffle:\n            ds = ds.shuffle(buffer_size=len(labels), seed=random_state)\n        return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n    train_ds = make_ds(X_train, S_train, y_train, shuffle=True)\n    val_ds   = make_ds(X_val,   S_val,   y_val,   shuffle=False)\n    test_ds  = make_ds(X_test,  S_test,  y_test,  shuffle=False)\n\n    return train_ds, val_ds, test_ds\n\ntrain_ds, val_ds, test_ds = load_and_split_multimodal_data(\n    sensor_csv_path=  \"/kaggle/input/gas-dataset/zkwgkjkjn9-2/Gas Sensors Measurements/Gas_Sensors_Measurements.csv\",\n    image_data_dir=\"/kaggle/input/gas-dataset/zkwgkjkjn9-2/Thermal Camera Images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:35:33.882322Z","iopub.execute_input":"2025-05-04T22:35:33.882587Z","iopub.status.idle":"2025-05-04T22:35:59.407150Z","shell.execute_reply.started":"2025-05-04T22:35:33.882568Z","shell.execute_reply":"2025-05-04T22:35:59.406418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RandomSensorDropout(tf.keras.layers.Layer):\n    \"\"\"\n    Layer that randomly zeros individual sensor channels with a given rate during training.\n    Supports proper serialization.\n    \"\"\"\n    def __init__(self, rate=0.3, **kwargs):\n        super().__init__(**kwargs)\n        self.rate = rate\n\n    def call(self, inputs, training=False):\n        if training and self.rate > 0.0:\n            mask = tf.cast(tf.random.uniform(tf.shape(inputs)) > self.rate, inputs.dtype)\n            return inputs * mask\n        return inputs\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"rate\": self.rate})\n        return config\n    \n\n# --------------- Monte Carlo Dropout Layers ---------------------    \nclass MCDropout(tf.keras.layers.Dropout):\n    \"\"\"\n    Dropout that is active both at train *and* inference time,\n    so we can sample N stochastic forward passes.\n    \"\"\"\n    def call(self, inputs, training=None):\n        # Force dropout even in inference\n        return super().call(inputs, training=True)\n    \n\nclass MCSpatialDropout2D(tf.keras.layers.SpatialDropout2D):\n    \"\"\"\n    Dropout that is active both at train *and* inference time,\n    so we can sample N stochastic forward passes.\n    \"\"\"\n    def call(self, inputs, training=None):\n        # Force dropout even in inference\n        return super().call(inputs, training=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:35:59.408692Z","iopub.execute_input":"2025-05-04T22:35:59.408990Z","iopub.status.idle":"2025-05-04T22:35:59.415365Z","shell.execute_reply.started":"2025-05-04T22:35:59.408972Z","shell.execute_reply":"2025-05-04T22:35:59.414655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_multimodal_model(\n    img_shape=(120, 160, 3),\n    input_dim=7,\n    sensor_dropout_rate=0.3,\n    layer_dropout=0.5,\n    sensor_units=32,\n    img_dense=64,\n    fusion_dense=64,\n    output_units=4,\n    lr=1e-4\n):\n    \"\"\"\n    Intermediate fusion of sensor and image branches.\n    Enhanced image branch with deeper layers and normalization.\n    \"\"\"\n    # Sensor input\n    inp = tf.keras.Input(shape=(input_dim,), name=\"sensor_input\")\n    x = RandomSensorDropout(sensor_dropout_rate, name=\"sensor_dropout\")(inp)\n    x = tf.keras.layers.Dense(224, activation=\"relu\")(x)\n    x = MCDropout(0.036)(x)\n    s = tf.keras.layers.Dense(240, activation=\"relu\")(x)\n\n    # Image input\n    i_in = tf.keras.Input(shape=img_shape, name=\"image_input\")\n    x = tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\" ,use_bias=False)(i_in)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n\n    x = tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n\n    x = tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = MCSpatialDropout2D(0.2)(x)\n\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(img_dense, activation=\"relu\")(x)\n    x = MCDropout(layer_dropout)(x)\n\n    # Fusion\n    fused = tf.keras.layers.Concatenate()([s, x])\n    y = tf.keras.layers.Dense(fusion_dense, activation=\"relu\")(fused)\n    y = MCDropout(layer_dropout)(y)\n    out = tf.keras.layers.Dense(output_units, activation=\"softmax\", name=\"output\")(y)\n\n    # Model compile\n    model = tf.keras.Model([inp, i_in], out, name=\"multimodal\")\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=7.07e-04),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:35:59.415969Z","iopub.execute_input":"2025-05-04T22:35:59.416160Z","iopub.status.idle":"2025-05-04T22:35:59.426771Z","shell.execute_reply.started":"2025-05-04T22:35:59.416137Z","shell.execute_reply":"2025-05-04T22:35:59.426180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_multimodal_model()\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    'best_mc_sensor_model.keras', monitor='val_accuracy',\n    save_best_only=True, mode='max' \n)\nmodel.fit(train_ds , validation_data = val_ds , epochs = 100 , batch_size = 32 , callbacks = [checkpoint])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:35:59.428077Z","iopub.execute_input":"2025-05-04T22:35:59.428477Z","iopub.status.idle":"2025-05-04T22:36:51.375086Z","shell.execute_reply.started":"2025-05-04T22:35:59.428461Z","shell.execute_reply":"2025-05-04T22:36:51.374527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model = tf.keras.models.load_model(\n        'best_mc_sensor_model.keras',\n        custom_objects={\"RandomSensorDropout\": RandomSensorDropout, \"MCDropout\": MCDropout,\"MCSpatialDropout2D\": MCSpatialDropout2D}\n    )\ndef predict_mc(model, dataset, T=50):\n    all_preds = []\n    all_labels = []\n    for sens_batch, lbl_batch in dataset:\n        preds_t = [model(sens_batch).numpy() for _ in range(T)]\n        preds_t = np.stack(preds_t, axis=0)  # (T, batch, classes)\n        mean_preds = preds_t.mean(axis=0)    # (batch, classes)\n        all_preds.append(mean_preds)\n        all_labels.append(lbl_batch.numpy())\n    all_preds = np.concatenate(all_preds, axis=0)\n    all_labels = np.concatenate(all_labels, axis=0)\n    y_pred = np.argmax(all_preds, axis=1)\n    return np.mean(y_pred == all_labels)\nacc = predict_mc(best_model , test_ds)\nprint(\"testing accuracy is \" ,acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:39:40.904993Z","iopub.execute_input":"2025-05-04T22:39:40.905618Z","iopub.status.idle":"2025-05-04T22:40:11.048962Z","shell.execute_reply.started":"2025-05-04T22:39:40.905593Z","shell.execute_reply":"2025-05-04T22:40:11.048317Z"}},"outputs":[],"execution_count":null}]}
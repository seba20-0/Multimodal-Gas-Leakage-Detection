{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T12:29:12.178734Z",
     "iopub.status.busy": "2025-05-04T12:29:12.178461Z",
     "iopub.status.idle": "2025-05-04T12:29:12.197061Z",
     "shell.execute_reply": "2025-05-04T12:29:12.196505Z",
     "shell.execute_reply.started": "2025-05-04T12:29:12.178712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T10:35:40.145544Z",
     "iopub.status.busy": "2025-05-04T10:35:40.145057Z",
     "iopub.status.idle": "2025-05-04T10:35:40.156233Z",
     "shell.execute_reply": "2025-05-04T10:35:40.155559Z",
     "shell.execute_reply.started": "2025-05-04T10:35:40.145524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_split_multimodal_data(\n",
    "    sensor_csv_path: str,\n",
    "    image_data_dir: str,\n",
    "    test_size: float = 0.1,\n",
    "    val_size: float = 0.2,\n",
    "    batch_size: int = 32,\n",
    "    img_size: tuple = (120, 160),\n",
    "    random_state: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Load and split both sensor CSV and image folders into multimodal tf.data.Datasets.\n",
    "\n",
    "    Args:\n",
    "        sensor_csv_path: Path to the gas sensor CSV.\n",
    "        image_data_dir: Base directory of image class subfolders.\n",
    "        test_size: Fraction of data reserved for testing.\n",
    "        val_size: Fraction of remaining data reserved for validation.\n",
    "        batch_size: Batch size for tf.data pipelines.\n",
    "        img_size: Size to resize images to (height, width).\n",
    "        random_state: Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        train_ds, val_ds, test_ds: tf.data.Dataset yielding ((sensor, image), label).\n",
    "    \"\"\"\n",
    "    # 1) Load sensor CSV\n",
    "    sdf = pd.read_csv(sensor_csv_path)\n",
    "    sdf = sdf.drop(columns=[\"Serial Number\"], errors='ignore')\n",
    "    sdf['Gas'] = sdf['Gas'].astype('category').cat.codes\n",
    "\n",
    "    # Build image filename column\n",
    "    sdf['Image_File'] = sdf['Corresponding Image Name'].astype(str) + \".png\"\n",
    "\n",
    "    # Extract sensor features and labels\n",
    "    sensor_cols = [c for c in sdf.columns if c not in ['Gas', 'Corresponding Image Name', 'Image_File']]\n",
    "    sensors = sdf[sensor_cols].values.astype('float32')\n",
    "    labels = sdf['Gas'].values.astype('int32')\n",
    "\n",
    "    # Normalize sensors\n",
    "    scaler = StandardScaler().fit(sensors)\n",
    "    sensors = scaler.transform(sensors)\n",
    "\n",
    "    # Map image names to full paths\n",
    "    base = image_data_dir\n",
    "    def find_path(fname):\n",
    "        for cls in os.listdir(base):\n",
    "            p = os.path.join(base, cls, fname)\n",
    "            if os.path.exists(p):\n",
    "                return p\n",
    "        return None\n",
    "\n",
    "    paths = np.array(sdf['Image_File'].map(find_path))\n",
    "    valid = ~pd.isna(paths)\n",
    "\n",
    "    sensors = sensors[valid]\n",
    "    paths   = paths[valid]\n",
    "    labels  = labels[valid]\n",
    "\n",
    "    # Split multimodal arrays\n",
    "    X_temp, X_test, S_temp, S_test, y_temp, y_test = train_test_split(\n",
    "        paths, sensors, labels,\n",
    "        test_size=test_size, stratify=labels, random_state=random_state\n",
    "    )\n",
    "    val_frac = val_size / (1 - test_size)\n",
    "    X_train, X_val, S_train, S_val, y_train, y_val = train_test_split(\n",
    "        X_temp, S_temp, y_temp,\n",
    "        test_size=val_frac, stratify=y_temp, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Define loader\n",
    "    def loader(path, sens, lab):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_png(img, channels=3)\n",
    "        img = tf.image.resize(img, img_size)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        sens = tf.cast(sens, tf.float32)\n",
    "        return (sens, img), lab\n",
    "\n",
    "    # Build tf.data datasets\n",
    "    def make_ds(paths, sensors, labels, shuffle=False):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((paths, sensors, labels))\n",
    "        ds = ds.map(loader, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(buffer_size=len(labels), seed=random_state)\n",
    "        return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    train_ds = make_ds(X_train, S_train, y_train, shuffle=True)\n",
    "    val_ds   = make_ds(X_val,   S_val,   y_val,   shuffle=False)\n",
    "    test_ds  = make_ds(X_test,  S_test,  y_test,  shuffle=False)\n",
    "\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T10:39:58.080771Z",
     "iopub.status.busy": "2025-05-04T10:39:58.080491Z",
     "iopub.status.idle": "2025-05-04T10:40:48.190843Z",
     "shell.execute_reply": "2025-05-04T10:40:48.190096Z",
     "shell.execute_reply.started": "2025-05-04T10:39:58.080750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = load_and_split_multimodal_data(\n",
    "    sensor_csv_path= \"../dataset/Gas Sensors Measurements/Gas_Sensors_Measurements.csv\",\n",
    "    image_data_dir= \"../dataset/Thermal Camera Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T10:40:48.192329Z",
     "iopub.status.busy": "2025-05-04T10:40:48.192037Z",
     "iopub.status.idle": "2025-05-04T10:40:48.198551Z",
     "shell.execute_reply": "2025-05-04T10:40:48.197984Z",
     "shell.execute_reply.started": "2025-05-04T10:40:48.192308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RandomSensorDropout(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Layer that randomly zeros individual sensor channels with a given rate during training.\n",
    "    Supports proper serialization.\n",
    "    \"\"\"\n",
    "    def __init__(self, rate=0.3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        if training and self.rate > 0.0:\n",
    "            mask = tf.cast(tf.random.uniform(tf.shape(inputs)) > self.rate, inputs.dtype)\n",
    "            return inputs * mask\n",
    "        return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"rate\": self.rate})\n",
    "        return config\n",
    "    \n",
    "\n",
    "# --------------- Monte Carlo Dropout Layers ---------------------    \n",
    "class MCDropout(tf.keras.layers.Dropout):\n",
    "    \"\"\"\n",
    "    Dropout that is active both at train *and* inference time,\n",
    "    so we can sample N stochastic forward passes.\n",
    "    \"\"\"\n",
    "    def call(self, inputs, training=None):\n",
    "        # Force dropout even in inference\n",
    "        return super().call(inputs, training=True)\n",
    "        \n",
    "class MCSpatialDropout2D(tf.keras.layers.SpatialDropout2D):\n",
    "    \"\"\"\n",
    "    Dropout that is active both at train *and* inference time,\n",
    "    so we can sample N stochastic forward passes.\n",
    "    \"\"\"\n",
    "    def call(self, inputs, training=None):\n",
    "        # Force dropout even in inference\n",
    "        return super().call(inputs, training=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T10:40:48.199445Z",
     "iopub.status.busy": "2025-05-04T10:40:48.199267Z",
     "iopub.status.idle": "2025-05-04T10:40:48.224476Z",
     "shell.execute_reply": "2025-05-04T10:40:48.223984Z",
     "shell.execute_reply.started": "2025-05-04T10:40:48.199430Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_multimodal_model(\n",
    "    img_shape=(120, 160, 3),\n",
    "    input_dim=7,\n",
    "    sensor_dropout_rate=0.3,\n",
    "    layer_dropout=0.5,\n",
    "    sensor_units=32,\n",
    "    img_dense=64,\n",
    "    fusion_dense=64,\n",
    "    output_units=4,\n",
    "    lr=1e-4\n",
    "):\n",
    "    \"\"\"\n",
    "    Intermediate fusion of sensor and image branches.\n",
    "    Enhanced image branch with deeper layers and normalization.\n",
    "    \"\"\"\n",
    "    # Sensor input\n",
    "    s_in = tf.keras.Input(shape=(input_dim,), name=\"sensor_input\")\n",
    "    s = RandomSensorDropout(sensor_dropout_rate, name=\"sensor_dropout\")(s_in)\n",
    "    s = tf.keras.layers.Dense(sensor_units, activation=\"relu\")(s)\n",
    "    s = MCDropout(layer_dropout)(s)\n",
    "\n",
    "    # Image input\n",
    "    i_in = tf.keras.Input(shape=img_shape, name=\"image_input\")\n",
    "    x = tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\" ,use_bias=False)(i_in)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\", use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = MCSpatialDropout2D(0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(img_dense, activation=\"relu\")(x)\n",
    "    x = MCDropout(layer_dropout)(x)\n",
    "\n",
    "    # Fusion\n",
    "    fused = tf.keras.layers.Concatenate()([s, x])\n",
    "    y = tf.keras.layers.Dense(fusion_dense, activation=\"relu\")(fused)\n",
    "    y = MCDropout(layer_dropout)(y)\n",
    "    out = tf.keras.layers.Dense(output_units, activation=\"softmax\", name=\"output\")(y)\n",
    "\n",
    "    # Model compile\n",
    "    model = tf.keras.Model([s_in, i_in], out, name=\"multimodal\")\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T10:59:08.822052Z",
     "iopub.status.busy": "2025-05-04T10:59:08.821352Z",
     "iopub.status.idle": "2025-05-04T11:43:45.511120Z",
     "shell.execute_reply": "2025-05-04T11:43:45.510376Z",
     "shell.execute_reply.started": "2025-05-04T10:59:08.822028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predict_mc(model, dataset, T=50):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for (img_batch, sens_batch), lbl_batch in dataset:\n",
    "        # run T stochastic passes\n",
    "        preds_t = [\n",
    "            model((img_batch, sens_batch), training=True).numpy()\n",
    "            for _ in range(T)\n",
    "        ]\n",
    "        # stack & average: (T, batch, classes) → (batch, classes)\n",
    "        mean_preds = np.stack(preds_t, axis=0).mean(axis=0)\n",
    "        all_preds.append(mean_preds)\n",
    "        all_labels.append(lbl_batch.numpy())\n",
    "\n",
    "    all_preds  = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    y_pred = np.argmax(all_preds, axis=1)\n",
    "    return np.mean(y_pred == all_labels)\n",
    "\n",
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5 , 0.6 , 0.7 , 0.8 , 0.9]\n",
    "val_accuracies = []\n",
    "\n",
    "for rate in dropout_rates:\n",
    "    model = build_multimodal_model(input_dim=7, sensor_dropout_rate=rate)\n",
    "    ckpt_path = f\"best_sensor_dropout_{rate:.1f}.keras\"\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        ckpt_path,\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    early_stop_cb = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",   # same metric as the checkpoint\n",
    "    mode=\"max\",\n",
    "    patience=10,               # stop after 10 epochs with no improvement\n",
    "    restore_best_weights=True # load best weights back into the model\n",
    "    )\n",
    "        \n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=100 , callbacks=[checkpoint_cb, early_stop_cb])\n",
    "    best_model = tf.keras.models.load_model(\n",
    "        ckpt_path,\n",
    "        custom_objects={\"RandomSensorDropout\": RandomSensorDropout , \"MCDropout\": MCDropout , \"MCSpatialDropout2D\": MCSpatialDropout2D}\n",
    "    )\n",
    "    acc = predict_mc(best_model, test_ds, T=50)\n",
    "    val_accuracies.append(acc)\n",
    "    print(f\"Dropout={rate:.1f} → MC Test Accuracy = {acc:.4f}\")\n",
    "\n",
    "# Plot dropout rate vs MC test accuracy\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(dropout_rates, val_accuracies, marker='o')\n",
    "plt.title(\"Sensor Dropout Rate vs. MC Test Accuracy for Multimodal\")\n",
    "plt.xlabel(\"Sensor Dropout Rate\")\n",
    "plt.ylabel(\"MC Test Accuracy\")\n",
    "plt.xticks(dropout_rates)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7300692,
     "sourceId": 11635786,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

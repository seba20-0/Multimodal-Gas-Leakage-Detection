{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11635786,"sourceType":"datasetVersion","datasetId":7300692}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom deap import base, creator, tools, algorithms\nimport random\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T09:57:05.938149Z","iopub.execute_input":"2025-05-04T09:57:05.938625Z","iopub.status.idle":"2025-05-04T09:57:23.338875Z","shell.execute_reply.started":"2025-05-04T09:57:05.938564Z","shell.execute_reply":"2025-05-04T09:57:23.337897Z"}},"outputs":[{"name":"stderr","text":"2025-05-04 09:57:08.216549: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746352628.487683      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746352628.564394      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"class RandomSensorDropout(tf.keras.layers.Layer):\n    \"\"\"\n    Layer that randomly zeros individual sensor channels with a given rate during training.\n    Supports proper serialization.\n    \"\"\"\n    def __init__(self, rate=0.3, **kwargs):\n        super().__init__(**kwargs)\n        self.rate = rate\n\n    def call(self, inputs, training=False):\n        if training and self.rate > 0.0:\n            mask = tf.cast(tf.random.uniform(tf.shape(inputs)) > self.rate, inputs.dtype)\n            return inputs * mask\n        return inputs\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"rate\": self.rate})\n        return config\n    \n\n# --------------- Monte Carlo Dropout Layer ---------------------    \nclass MCDropout(tf.keras.layers.Dropout):\n    \"\"\"\n    Dropout that is active both at train *and* inference time,\n    so we can sample N stochastic forward passes.\n    \"\"\"\n    def call(self, inputs, training=None):\n        # Force dropout even in inference\n        return super().call(inputs, training=True)\n\n\n# --------------- Sensor Model ---------------------\n\ndef build_sensor_model(\n    input_dim=7,\n    sensor_dropout_rate=0.3,\n    layer_dropout = 0.5,\n    hidden_units=(64, 32),\n    output_units=4,\n    lr=1e-4\n):\n    \"\"\"\n    Sensor-only MLP with RandomSensorDropout option for ablation.\n    \"\"\"\n    inp = tf.keras.Input(shape=(input_dim,), name=\"sensor_input\")\n    x = RandomSensorDropout(sensor_dropout_rate, name=\"sensor_dropout\")(inp)\n    x = tf.keras.layers.Dense(hidden_units[0], activation=\"relu\")(x)\n    x = MCDropout(layer_dropout)(x)\n    x = tf.keras.layers.Dense(hidden_units[1], activation=\"relu\")(x)\n    x = MCDropout(layer_dropout)(x)\n    out = tf.keras.layers.Dense(output_units, activation=\"softmax\", name=\"output\")(x)\n\n    model = tf.keras.Model(inp, out, name=\"sensor_only\")\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(lr),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T09:57:23.340140Z","iopub.execute_input":"2025-05-04T09:57:23.340647Z","iopub.status.idle":"2025-05-04T09:57:23.434008Z","shell.execute_reply.started":"2025-05-04T09:57:23.340623Z","shell.execute_reply":"2025-05-04T09:57:23.433113Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load data as numpy arrays\nimport os, glob\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom tqdm import trange\n\n\ndef load_and_split_sensor_data(\n    csv_path: str,\n    test_size: float = 0.1,\n    val_size: float = 0.2,\n    random_state: int = 42\n):\n    \"\"\"\n    Load sensor CSV, preprocess (drop columns, encode labels, scale), and split into train/val/test.\n\n    Args:\n        csv_path: Path to the Gas Sensors Measurements CSV file.\n        test_size: Fraction of data reserved for final test set.\n        val_size: Fraction of remaining data reserved for validation.\n        random_state: Random seed for reproducibility.\n\n    Returns:\n        train_ds: tf.data.Dataset for training (features, labels).\n        val_ds: tf.data.Dataset for validation.\n        test_ds: tf.data.Dataset for testing.\n    \"\"\"\n    # 1) Load and clean\n    df = pd.read_csv(csv_path)\n    # drop unused columns\n    df = df.drop(columns=[\"Serial Number\", \"Corresponding Image Name\"], errors='ignore')\n    # encode labels\n    df['Gas'] = df['Gas'].astype('category').cat.codes\n\n    # 2) Extract features and labels\n    feature_cols = [c for c in df.columns if c != 'Gas']\n    X = df[feature_cols].values.astype('float32')\n    y = df['Gas'].values.astype('int32')\n\n    # 3) Scale features\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    # 4) Split into train+val and test\n    X_temp, X_test, y_temp, y_test = train_test_split(\n        X_scaled, y, test_size=test_size, stratify=y, random_state=random_state\n    )\n    # Split train_temp into train and val\n    val_fraction = val_size / (1 - test_size)\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_temp, y_temp, test_size=val_fraction,\n        stratify=y_temp, random_state=random_state\n    )\n\n    # 5) Build tf.data datasets\n    def make_ds(features, labels, batch_size=32, shuffle=False):\n        ds = tf.data.Dataset.from_tensor_slices((features, labels))\n        if shuffle:\n            ds = ds.shuffle(buffer_size=len(features), seed=random_state)\n        return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    num = X_train.shape[1]\n    batch_size = 32\n    train_ds = make_ds(X_train, y_train, batch_size, shuffle=True)\n    val_ds   = make_ds(X_val,   y_val,   batch_size, shuffle=False)\n    test_ds  = make_ds(X_test,  y_test,  batch_size, shuffle=False)\n\n    return train_ds, val_ds, test_ds,num\ncsv_path = \"/kaggle/input/gas-dataset/zkwgkjkjn9-2/Gas Sensors Measurements/Gas_Sensors_Measurements.csv\"\ntrain_ds, val_ds,test_ds, num = load_and_split_sensor_data(csv_path, 0.1, 0.2, 123)\n\noutput_units = len(np.unique([label.numpy() for _, label in train_ds.unbatch()]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T10:25:52.109743Z","iopub.execute_input":"2025-05-04T10:25:52.110073Z","iopub.status.idle":"2025-05-04T10:25:53.358962Z","shell.execute_reply.started":"2025-05-04T10:25:52.110048Z","shell.execute_reply":"2025-05-04T10:25:53.358237Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import random, numpy as np, tensorflow as tf\nfrom deap import base, creator, tools\nfrom tqdm import trange\n\n\n# ------------------------------------------------------------------\n# 1. Load tf.data datasets + meta info\ncsv_path = \"/kaggle/input/gas-dataset/zkwgkjkjn9-2/Gas Sensors Measurements/Gas_Sensors_Measurements.csv\"\ntrain_ds, val_ds, test_ds,num = load_and_split_sensor_data(csv_path, 0.1, 0.2, 123)\ninput_dim     = train_ds.element_spec[0].shape[-1]\noutput_units  = len(np.unique([y.numpy() for _, y in train_ds.unbatch()]))\n\n# ------------------------------------------------------------------\n# 2. Fitness: expect exactly three flat genes\ndef eval_individual(ind, train_ds, val_ds, test_ds, input_dim, output_units):\n    layer_do, h1, h2 = float(ind[0]), int(ind[1]), int(ind[2])\n\n    # quick validity check\n    if not (0. <= layer_do <= 1. and h1 > 0 and h2 > 0):\n        return (0.0,)\n\n    model = build_sensor_model(\n        input_dim     = input_dim,\n        sensor_dropout_rate = 0.3,\n        layer_dropout = layer_do,\n        hidden_units  = (h1, h2),\n        output_units  = output_units,\n        lr            = 1e-4\n    )\n    model.fit(train_ds, validation_data=val_ds, epochs=5, verbose=0)\n    _, acc = model.evaluate(val_ds, verbose=0)\n    tf.keras.backend.clear_session()\n    return (acc,)\n\n# ------------------------------------------------------------------\n# 3. DEAP setup (delete old classes if cell re‑run)\nfor cls in (\"FitnessMax\", \"Individual\"):\n    if cls in creator.__dict__:\n        del creator.__dict__[cls]\n\ncreator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\ncreator.create(\"Individual\", list, fitness=creator.FitnessMax)\n\ntoolbox = base.Toolbox()\ntoolbox.register(\"layer_do\", random.uniform, 0.0, 0.8)\ntoolbox.register(\"h1\",       random.randrange, 16, 257, 16)\ntoolbox.register(\"h2\",       random.randrange, 16, 257, 16)\n\n# ---- IMPORTANT: create a *flat* 3‑gene list ----------------------\ntoolbox.register(\n    \"individual\",\n    tools.initIterate,\n    creator.Individual,\n    lambda: [toolbox.layer_do(), toolbox.h1(), toolbox.h2()]\n)\n# -----------------------------------------------------------------\n\ntoolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\ntoolbox.register(\"evaluate\",   eval_individual,\n                 train_ds=train_ds, val_ds=val_ds, test_ds=test_ds,\n                 input_dim=input_dim, output_units=output_units)\ntoolbox.register(\"mate\", tools.cxTwoPoint)\n\n# custom mutation – return the list itself (not tuple!)\ndef mutate_ind(ind, indpb):\n    if random.random() < indpb:\n        ind[0] = random.uniform(0.0, 0.8)\n    if random.random() < indpb:\n        ind[1] = random.randrange(16, 257, 16)\n    if random.random() < indpb:\n        ind[2] = random.randrange(16, 257, 16)\n    return ind,                     # <- DEAP expects a tuple *of* individuals\n\ntoolbox.register(\"mutate\", mutate_ind, indpb=0.2)\ntoolbox.register(\"select\", tools.selTournament, tournsize=3)\n\n# ------------------------------------------------------------------\n# 4. Evolve\nPOP, NGEN, CX_PB, MUT_PB = 20, 30, 0.5, 0.2\npop = toolbox.population(n=POP)\nhof = tools.HallOfFame(1)\n\nfor _ in trange(NGEN, desc=\"GA generations\"):\n    offspring = list(map(toolbox.clone, toolbox.select(pop, len(pop))))\n    for c1, c2 in zip(offspring[::2], offspring[1::2]):\n        if random.random() < CX_PB:\n            toolbox.mate(c1, c2)\n            del c1.fitness.values, c2.fitness.values\n    for m in offspring:\n        if random.random() < MUT_PB:\n            toolbox.mutate(m)\n            del m.fitness.values\n    invalid = [ind for ind in offspring if not ind.fitness.valid]\n    for ind, fit in zip(invalid, map(toolbox.evaluate, invalid)):\n        ind.fitness.values = fit\n    pop[:] = offspring\n    hof.update(pop)\n\nbest = hof[0]\nprint(f\"\\nBest → dropout={best[0]:.3f}, hidden={best[1]},{best[2]}, \"\n      f\"val_acc={best.fitness.values[0]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T10:56:52.236377Z","iopub.execute_input":"2025-05-04T10:56:52.236732Z","iopub.status.idle":"2025-05-04T11:38:36.699701Z","shell.execute_reply.started":"2025-05-04T10:56:52.236709Z","shell.execute_reply":"2025-05-04T11:38:36.698798Z"}},"outputs":[{"name":"stderr","text":"GA generations: 100%|██████████| 30/30 [41:43<00:00, 83.44s/it] ","output_type":"stream"},{"name":"stdout","text":"\nBest → dropout=0.046, hidden=256,224, val_acc=0.9094\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# with learning rate","metadata":{}},{"cell_type":"code","source":"import random, numpy as np, tensorflow as tf\nfrom deap import base, creator, tools\nfrom tqdm import trange\n\n# ------------------------------------------------------------------\n# 1. Load data\ncsv_path = \"/kaggle/input/gas-dataset/zkwgkjkjn9-2/Gas Sensors Measurements/Gas_Sensors_Measurements.csv\"\ntrain_ds, val_ds, test_ds, num = load_and_split_sensor_data(csv_path, 0.1, 0.2, 123)\ninput_dim     = train_ds.element_spec[0].shape[-1]\noutput_units  = len(np.unique([y.numpy() for _, y in train_ds.unbatch()]))\n\n# ------------------------------------------------------------------\n# 2. Fitness: genome = [dropout, h1, h2, log10_lr]\ndef eval_individual(ind, train_ds, val_ds, input_dim, output_units):\n    layer_do, h1, h2, log_lr = float(ind[0]), int(ind[1]), int(ind[2]), float(ind[3])\n    if not (0. <= layer_do <= 1. and h1 > 0 and h2 > 0 and -7 <= log_lr <= -2):\n        return (0.0,)\n\n    lr = 10 ** log_lr\n    model = build_sensor_model(\n        input_dim            = input_dim,\n        sensor_dropout_rate  = 0.3,\n        layer_dropout        = layer_do,\n        hidden_units         = (h1, h2),\n        output_units         = output_units,\n        lr                   = lr\n    )\n    callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n    model.fit(train_ds, validation_data=val_ds, epochs=25, callbacks=[callback], verbose=0)\n    _, acc = model.evaluate(val_ds, verbose=0)\n    tf.keras.backend.clear_session()\n    return (acc,)\n\n# ------------------------------------------------------------------\n# 3. DEAP setup\nfor cls in (\"FitnessMax\", \"Individual\"):\n    if cls in creator.__dict__: del creator.__dict__[cls]\n\ncreator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\ncreator.create(\"Individual\", list, fitness=creator.FitnessMax)\n\ntoolbox = base.Toolbox()\ntoolbox.register(\"layer_do\", random.uniform, 0.0, 0.8)\ntoolbox.register(\"h1\",       random.randrange, 16, 257, 16)\ntoolbox.register(\"h2\",       random.randrange, 16, 257, 16)\ntoolbox.register(\"log_lr\",   random.uniform, -5, -3)        # log₁₀ learning rate\n\ntoolbox.register(\n    \"individual\",\n    tools.initIterate,\n    creator.Individual,\n    lambda: [toolbox.layer_do(), toolbox.h1(), toolbox.h2(), toolbox.log_lr()]\n)\n\ntoolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\ntoolbox.register(\"evaluate\",   eval_individual,\n                 train_ds=train_ds, val_ds=val_ds,\n                 input_dim=input_dim, output_units=output_units)\ntoolbox.register(\"mate\", tools.cxTwoPoint)\n\n# Gaussian‑style jitter mutation\ndef mutate_ind(ind, indpb=0.2):\n    if random.random() < indpb:\n        ind[0] = np.clip(ind[0] + np.random.normal(0, 0.05), 0.0, 0.8)\n    if random.random() < indpb:\n        ind[1] = max(16, min(256, ind[1] + random.choice([-16, 16])))\n    if random.random() < indpb:\n        ind[2] = max(16, min(256, ind[2] + random.choice([-16, 16])))\n    if random.random() < indpb:\n        ind[3] = np.clip(ind[3] + np.random.normal(0, 0.25), -5, -3)\n    return ind,\n\ntoolbox.register(\"mutate\", mutate_ind)\ntoolbox.register(\"select\", tools.selTournament, tournsize=3)\n\n# ------------------------------------------------------------------\n# 4. Evolve\nPOP, NGEN, CX_PB, MUT_PB = 40, 50, 0.5, 0.2\npop = toolbox.population(n=POP)\nhof = tools.HallOfFame(1)\n\nfor _ in trange(NGEN, desc=\"GA generations\"):\n    offspring = list(map(toolbox.clone, toolbox.select(pop, len(pop))))\n    for c1, c2 in zip(offspring[::2], offspring[1::2]):\n        if random.random() < CX_PB:\n            toolbox.mate(c1, c2)\n            del c1.fitness.values, c2.fitness.values\n    for m in offspring:\n        if random.random() < MUT_PB:\n            toolbox.mutate(m)\n            del m.fitness.values\n    invalid = [ind for ind in offspring if not ind.fitness.valid]\n    for ind, fit in zip(invalid, map(toolbox.evaluate, invalid)):\n        ind.fitness.values = fit\n    elite = tools.selBest(pop, 2)          # elitism\n    pop[:] = elite + offspring[:-2]\n    hof.update(pop)\n\nbest = hof[0]\nprint(f\"\\nBest → dropout={best[0]:.3f}, hidden={best[1]},{best[2]}, \"\n      f\"lr={10**best[3]:.2e}, val_acc={best.fitness.values[0]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T12:25:53.886238Z","iopub.execute_input":"2025-05-04T12:25:53.886890Z","iopub.status.idle":"2025-05-04T18:02:28.464482Z","shell.execute_reply.started":"2025-05-04T12:25:53.886858Z","shell.execute_reply":"2025-05-04T18:02:28.463252Z"}},"outputs":[{"name":"stderr","text":"GA generations: 100%|██████████| 50/50 [5:36:33<00:00, 403.86s/it]  ","output_type":"stream"},{"name":"stdout","text":"\nBest → dropout=0.036, hidden=224,240, lr=7.07e-04, val_acc=0.9531\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23}]}
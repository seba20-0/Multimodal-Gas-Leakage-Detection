{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T09:57:05.938625Z",
     "iopub.status.busy": "2025-05-04T09:57:05.938149Z",
     "iopub.status.idle": "2025-05-04T09:57:23.338875Z",
     "shell.execute_reply": "2025-05-04T09:57:23.337897Z",
     "shell.execute_reply.started": "2025-05-04T09:57:05.938564Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 09:57:08.216549: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746352628.487683      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746352628.564394      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T09:57:23.340647Z",
     "iopub.status.busy": "2025-05-04T09:57:23.340140Z",
     "iopub.status.idle": "2025-05-04T09:57:23.434008Z",
     "shell.execute_reply": "2025-05-04T09:57:23.433113Z",
     "shell.execute_reply.started": "2025-05-04T09:57:23.340623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RandomSensorDropout(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Layer that randomly zeros individual sensor channels with a given rate during training.\n",
    "    Supports proper serialization.\n",
    "    \"\"\"\n",
    "    def __init__(self, rate=0.3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        if training and self.rate > 0.0:\n",
    "            mask = tf.cast(tf.random.uniform(tf.shape(inputs)) > self.rate, inputs.dtype)\n",
    "            return inputs * mask\n",
    "        return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"rate\": self.rate})\n",
    "        return config\n",
    "    \n",
    "\n",
    "# --------------- Monte Carlo Dropout Layer ---------------------    \n",
    "class MCDropout(tf.keras.layers.Dropout):\n",
    "    \"\"\"\n",
    "    Dropout that is active both at train *and* inference time,\n",
    "    so we can sample N stochastic forward passes.\n",
    "    \"\"\"\n",
    "    def call(self, inputs, training=None):\n",
    "        # Force dropout even in inference\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "\n",
    "# --------------- Sensor Model ---------------------\n",
    "\n",
    "def build_sensor_model(\n",
    "    input_dim=7,\n",
    "    sensor_dropout_rate=0.3,\n",
    "    layer_dropout = 0.5,\n",
    "    hidden_units=(64, 32),\n",
    "    output_units=4,\n",
    "    lr=1e-4\n",
    "):\n",
    "    \"\"\"\n",
    "    Sensor-only MLP with RandomSensorDropout option for ablation.\n",
    "    \"\"\"\n",
    "    inp = tf.keras.Input(shape=(input_dim,), name=\"sensor_input\")\n",
    "    x = RandomSensorDropout(sensor_dropout_rate, name=\"sensor_dropout\")(inp)\n",
    "    x = tf.keras.layers.Dense(hidden_units[0], activation=\"relu\")(x)\n",
    "    x = MCDropout(layer_dropout)(x)\n",
    "    x = tf.keras.layers.Dense(hidden_units[1], activation=\"relu\")(x)\n",
    "    x = MCDropout(layer_dropout)(x)\n",
    "    out = tf.keras.layers.Dense(output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, out, name=\"sensor_only\")\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T10:25:52.110073Z",
     "iopub.status.busy": "2025-05-04T10:25:52.109743Z",
     "iopub.status.idle": "2025-05-04T10:25:53.358962Z",
     "shell.execute_reply": "2025-05-04T10:25:53.358237Z",
     "shell.execute_reply.started": "2025-05-04T10:25:52.110048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load data as numpy arrays\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "def load_and_split_sensor_data(\n",
    "    csv_path: str,\n",
    "    test_size: float = 0.1,\n",
    "    val_size: float = 0.2,\n",
    "    random_state: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Load sensor CSV, preprocess (drop columns, encode labels, scale), and split into train/val/test.\n",
    "\n",
    "    Args:\n",
    "        csv_path: Path to the Gas Sensors Measurements CSV file.\n",
    "        test_size: Fraction of data reserved for final test set.\n",
    "        val_size: Fraction of remaining data reserved for validation.\n",
    "        random_state: Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        train_ds: tf.data.Dataset for training (features, labels).\n",
    "        val_ds: tf.data.Dataset for validation.\n",
    "        test_ds: tf.data.Dataset for testing.\n",
    "    \"\"\"\n",
    "    # 1) Load and clean\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # drop unused columns\n",
    "    df = df.drop(columns=[\"Serial Number\", \"Corresponding Image Name\"], errors='ignore')\n",
    "    # encode labels\n",
    "    df['Gas'] = df['Gas'].astype('category').cat.codes\n",
    "\n",
    "    # 2) Extract features and labels\n",
    "    feature_cols = [c for c in df.columns if c != 'Gas']\n",
    "    X = df[feature_cols].values.astype('float32')\n",
    "    y = df['Gas'].values.astype('int32')\n",
    "\n",
    "    # 3) Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 4) Split into train+val and test\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    # Split train_temp into train and val\n",
    "    val_fraction = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_fraction,\n",
    "        stratify=y_temp, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 5) Build tf.data datasets\n",
    "    def make_ds(features, labels, batch_size=32, shuffle=False):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(buffer_size=len(features), seed=random_state)\n",
    "        return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    num = X_train.shape[1]\n",
    "    batch_size = 32\n",
    "    train_ds = make_ds(X_train, y_train, batch_size, shuffle=True)\n",
    "    val_ds   = make_ds(X_val,   y_val,   batch_size, shuffle=False)\n",
    "    test_ds  = make_ds(X_test,  y_test,  batch_size, shuffle=False)\n",
    "\n",
    "    return train_ds, val_ds, test_ds,num\n",
    "csv_path = \"/kaggle/input/gas-dataset/zkwgkjkjn9-2/Gas Sensors Measurements/Gas_Sensors_Measurements.csv\"\n",
    "train_ds, val_ds,test_ds, num = load_and_split_sensor_data(csv_path, 0.1, 0.2, 123)\n",
    "\n",
    "output_units = len(np.unique([label.numpy() for _, label in train_ds.unbatch()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T10:56:52.236732Z",
     "iopub.status.busy": "2025-05-04T10:56:52.236377Z",
     "iopub.status.idle": "2025-05-04T11:38:36.699701Z",
     "shell.execute_reply": "2025-05-04T11:38:36.698798Z",
     "shell.execute_reply.started": "2025-05-04T10:56:52.236709Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GA generations: 100%|██████████| 30/30 [41:43<00:00, 83.44s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best → dropout=0.046, hidden=256,224, val_acc=0.9094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random, numpy as np, tensorflow as tf\n",
    "from deap import base, creator, tools\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Load tf.data datasets + meta info\n",
    "csv_path = \"/kaggle/input/gas-dataset/zkwgkjkjn9-2/Gas Sensors Measurements/Gas_Sensors_Measurements.csv\"\n",
    "train_ds, val_ds, test_ds,num = load_and_split_sensor_data(csv_path, 0.1, 0.2, 123)\n",
    "input_dim     = train_ds.element_spec[0].shape[-1]\n",
    "output_units  = len(np.unique([y.numpy() for _, y in train_ds.unbatch()]))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Fitness: expect exactly three flat genes\n",
    "def eval_individual(ind, train_ds, val_ds, test_ds, input_dim, output_units):\n",
    "    layer_do, h1, h2 = float(ind[0]), int(ind[1]), int(ind[2])\n",
    "\n",
    "    # quick validity check\n",
    "    if not (0. <= layer_do <= 1. and h1 > 0 and h2 > 0):\n",
    "        return (0.0,)\n",
    "\n",
    "    model = build_sensor_model(\n",
    "        input_dim     = input_dim,\n",
    "        sensor_dropout_rate = 0.3,\n",
    "        layer_dropout = layer_do,\n",
    "        hidden_units  = (h1, h2),\n",
    "        output_units  = output_units,\n",
    "        lr            = 1e-4\n",
    "    )\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=5, verbose=0)\n",
    "    _, acc = model.evaluate(val_ds, verbose=0)\n",
    "    tf.keras.backend.clear_session()\n",
    "    return (acc,)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. DEAP setup (delete old classes if cell re‑run)\n",
    "for cls in (\"FitnessMax\", \"Individual\"):\n",
    "    if cls in creator.__dict__:\n",
    "        del creator.__dict__[cls]\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"layer_do\", random.uniform, 0.0, 0.8)\n",
    "toolbox.register(\"h1\",       random.randrange, 16, 257, 16)\n",
    "toolbox.register(\"h2\",       random.randrange, 16, 257, 16)\n",
    "\n",
    "# ---- IMPORTANT: create a *flat* 3‑gene list ----------------------\n",
    "toolbox.register(\n",
    "    \"individual\",\n",
    "    tools.initIterate,\n",
    "    creator.Individual,\n",
    "    lambda: [toolbox.layer_do(), toolbox.h1(), toolbox.h2()]\n",
    ")\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\",   eval_individual,\n",
    "                 train_ds=train_ds, val_ds=val_ds, test_ds=test_ds,\n",
    "                 input_dim=input_dim, output_units=output_units)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "\n",
    "# custom mutation – return the list itself (not tuple!)\n",
    "def mutate_ind(ind, indpb):\n",
    "    if random.random() < indpb:\n",
    "        ind[0] = random.uniform(0.0, 0.8)\n",
    "    if random.random() < indpb:\n",
    "        ind[1] = random.randrange(16, 257, 16)\n",
    "    if random.random() < indpb:\n",
    "        ind[2] = random.randrange(16, 257, 16)\n",
    "    return ind,                     # <- DEAP expects a tuple *of* individuals\n",
    "\n",
    "toolbox.register(\"mutate\", mutate_ind, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Evolve\n",
    "POP, NGEN, CX_PB, MUT_PB = 20, 30, 0.5, 0.2\n",
    "pop = toolbox.population(n=POP)\n",
    "hof = tools.HallOfFame(1)\n",
    "\n",
    "for _ in trange(NGEN, desc=\"GA generations\"):\n",
    "    offspring = list(map(toolbox.clone, toolbox.select(pop, len(pop))))\n",
    "    for c1, c2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CX_PB:\n",
    "            toolbox.mate(c1, c2)\n",
    "            del c1.fitness.values, c2.fitness.values\n",
    "    for m in offspring:\n",
    "        if random.random() < MUT_PB:\n",
    "            toolbox.mutate(m)\n",
    "            del m.fitness.values\n",
    "    invalid = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    for ind, fit in zip(invalid, map(toolbox.evaluate, invalid)):\n",
    "        ind.fitness.values = fit\n",
    "    pop[:] = offspring\n",
    "    hof.update(pop)\n",
    "\n",
    "best = hof[0]\n",
    "print(f\"\\nBest → dropout={best[0]:.3f}, hidden={best[1]},{best[2]}, \"\n",
    "      f\"val_acc={best.fitness.values[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T12:25:53.886890Z",
     "iopub.status.busy": "2025-05-04T12:25:53.886238Z",
     "iopub.status.idle": "2025-05-04T18:02:28.464482Z",
     "shell.execute_reply": "2025-05-04T18:02:28.463252Z",
     "shell.execute_reply.started": "2025-05-04T12:25:53.886858Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GA generations: 100%|██████████| 50/50 [5:36:33<00:00, 403.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best → dropout=0.036, hidden=224,240, lr=7.07e-04, val_acc=0.9531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random, numpy as np, tensorflow as tf\n",
    "from deap import base, creator, tools\n",
    "from tqdm import trange\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Load data\n",
    "csv_path = \"../dataset/Gas Sensors Measurements/Gas_Sensors_Measurements.csv\"\n",
    "train_ds, val_ds, test_ds, num = load_and_split_sensor_data(csv_path, 0.1, 0.2, 123)\n",
    "input_dim     = train_ds.element_spec[0].shape[-1]\n",
    "output_units  = len(np.unique([y.numpy() for _, y in train_ds.unbatch()]))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Fitness: genome = [dropout, h1, h2, log10_lr]\n",
    "def eval_individual(ind, train_ds, val_ds, input_dim, output_units):\n",
    "    layer_do, h1, h2, log_lr = float(ind[0]), int(ind[1]), int(ind[2]), float(ind[3])\n",
    "    if not (0. <= layer_do <= 1. and h1 > 0 and h2 > 0 and -7 <= log_lr <= -2):\n",
    "        return (0.0,)\n",
    "\n",
    "    lr = 10 ** log_lr\n",
    "    model = build_sensor_model(\n",
    "        input_dim            = input_dim,\n",
    "        sensor_dropout_rate  = 0.3,\n",
    "        layer_dropout        = layer_do,\n",
    "        hidden_units         = (h1, h2),\n",
    "        output_units         = output_units,\n",
    "        lr                   = lr\n",
    "    )\n",
    "    callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=25, callbacks=[callback], verbose=0)\n",
    "    _, acc = model.evaluate(val_ds, verbose=0)\n",
    "    tf.keras.backend.clear_session()\n",
    "    return (acc,)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. DEAP setup\n",
    "for cls in (\"FitnessMax\", \"Individual\"):\n",
    "    if cls in creator.__dict__: del creator.__dict__[cls]\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"layer_do\", random.uniform, 0.0, 0.8)\n",
    "toolbox.register(\"h1\",       random.randrange, 16, 257, 16)\n",
    "toolbox.register(\"h2\",       random.randrange, 16, 257, 16)\n",
    "toolbox.register(\"log_lr\",   random.uniform, -5, -3)        # log₁₀ learning rate\n",
    "\n",
    "toolbox.register(\n",
    "    \"individual\",\n",
    "    tools.initIterate,\n",
    "    creator.Individual,\n",
    "    lambda: [toolbox.layer_do(), toolbox.h1(), toolbox.h2(), toolbox.log_lr()]\n",
    ")\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\",   eval_individual,\n",
    "                 train_ds=train_ds, val_ds=val_ds,\n",
    "                 input_dim=input_dim, output_units=output_units)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "\n",
    "# Gaussian‑style jitter mutation\n",
    "def mutate_ind(ind, indpb=0.2):\n",
    "    if random.random() < indpb:\n",
    "        ind[0] = np.clip(ind[0] + np.random.normal(0, 0.05), 0.0, 0.8)\n",
    "    if random.random() < indpb:\n",
    "        ind[1] = max(16, min(256, ind[1] + random.choice([-16, 16])))\n",
    "    if random.random() < indpb:\n",
    "        ind[2] = max(16, min(256, ind[2] + random.choice([-16, 16])))\n",
    "    if random.random() < indpb:\n",
    "        ind[3] = np.clip(ind[3] + np.random.normal(0, 0.25), -5, -3)\n",
    "    return ind,\n",
    "\n",
    "toolbox.register(\"mutate\", mutate_ind)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Evolve\n",
    "POP, NGEN, CX_PB, MUT_PB = 40, 50, 0.5, 0.2\n",
    "pop = toolbox.population(n=POP)\n",
    "hof = tools.HallOfFame(1)\n",
    "\n",
    "for _ in trange(NGEN, desc=\"GA generations\"):\n",
    "    offspring = list(map(toolbox.clone, toolbox.select(pop, len(pop))))\n",
    "    for c1, c2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CX_PB:\n",
    "            toolbox.mate(c1, c2)\n",
    "            del c1.fitness.values, c2.fitness.values\n",
    "    for m in offspring:\n",
    "        if random.random() < MUT_PB:\n",
    "            toolbox.mutate(m)\n",
    "            del m.fitness.values\n",
    "    invalid = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    for ind, fit in zip(invalid, map(toolbox.evaluate, invalid)):\n",
    "        ind.fitness.values = fit\n",
    "    elite = tools.selBest(pop, 2)          # elitism\n",
    "    pop[:] = elite + offspring[:-2]\n",
    "    hof.update(pop)\n",
    "\n",
    "best = hof[0]\n",
    "print(f\"\\nBest → dropout={best[0]:.3f}, hidden={best[1]},{best[2]}, \"\n",
    "      f\"lr={10**best[3]:.2e}, val_acc={best.fitness.values[0]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7300692,
     "sourceId": 11635786,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
